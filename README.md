# CMS Hospital Dataset Downloader

A Python script that automatically discovers, downloads, and processes all hospital-related datasets from the CMS Provider Data API.
The script is designed to run daily, perform incremental downloads, convert all CSV headers to snake_case, and save the processed files locally in parallel.

â¸»

## Features

1. Automatically discovers hospital datasets

Fetches dataset metadata from:

https://data.cms.gov/provider-data/api/1/metastore/schemas/dataset/items

Filters datasets whose metadata contains the theme â€œHospitalsâ€ (checking theme, tags, title, description).

â¸»

2. Downloads all CSV distributions

For each matching dataset, the script extracts all linked .csv files and downloads them.

â¸»

3. Parallel, asynchronous downloading

Uses aiohttp, asyncio, and a concurrency semaphore to download many files at once for high performance.


4. Converts all CSV headers to snake_case

Example conversion:

Original Header	Converted

Patients Rating of the Facility ==>	patients_rating_of_the_facility

The transformation:
	â€¢	lowercase
	
	â€¢	spaces â†’ _
	
	â€¢	remove punctuation
	
	â€¢	split camelCase â†’ snake_case
	
	â€¢	collapse repeated underscores


5. Incremental daily updates

The script stores metadata in:

metadata.json

This includes:
	â€¢	URL
	â€¢	filename
	â€¢	last_modified header
	â€¢	ETag
	â€¢	row, column counts
	â€¢	download timestamp

Next day:
The script checks remote ETag / Last-Modified and skips files that havenâ€™t changed.

This makes the script safe and efficient for daily scheduled runs.

â¸»

6. Platform independent

Runs on:
	â€¢	macOS
	â€¢	Linux
	â€¢	Windows

Uses only pip-installable libraries.

â¸»

## Project Structure

project_root/
â”‚
â”œâ”€â”€ cms_hospitals_downloader.py     # Main script
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ metadata.json                   # Auto-generated metadata tracking
â”‚
â””â”€â”€ data/                           # Auto-generated folder of processed CSVs
     â”œâ”€â”€ <dataset_id>/              # One folder per dataset
     â”‚      â”œâ”€â”€ <file>.csv
     â”œâ”€â”€ <dataset_id>/              
     â”‚      â”œâ”€â”€ <file>.csv

All downloaded and processed CSVs are inside /data/<dataset_id>/.

â¸»

## Installation

1. Clone or download this project

git clone <your-repo-url>

cd <project-folder>

2. Create a virtual environment

python3 -m venv ondemangrp_venv

source ondemangrp_venv/bin/activate     # macOS/Linux

ondemangrp_venv\Scripts\activate        # Windows

3. Install dependencies

pip3 install -r requirements.txt


â¸»

## How to Run the Script

Run directly:

python cms_hospitals_downloader.py

After completion, you will see:
	â€¢	metadata.json updated
	â€¢	Processed CSVs in the data/ folder
	â€¢	Headers fully converted to snake_case

â¸»

## Running Daily (Scheduled Execution)

Script is designed to be run daily using a scheduler:

ðŸŸ¦ macOS / Linux (cron)

0 2 * * * /usr/bin/python3 /path/to/cms_hospitals_downloader.py

ðŸŸª Windows (Task Scheduler)
	â€¢	Trigger: Daily â†’ 2:00 AM
	â€¢	Action: python cms_hospitals_downloader.py

The script is idempotent, meaning it only downloads updated files.

â¸»

## How Metadata Tracking Works (metadata.json)

Example entry:

{
  "HOSPITAL_GENERAL_INFORMATION::https://data.cms.gov/.../file.csv": {
    "url": "...",
    "filename": "Hospital_General_Information.csv",
    "etag": "\"abcd123\"",
    "last_modified": "Mon, 13 Jan 2025 10:18:01 GMT",
    "downloaded_at": "2025-11-29T16:44:00Z",
    "rows": 5431,
    "cols": 41
  }
}

On each run, the script:
	1.	Performs a HEAD request
	2.	Compares ETag / Last-Modified with saved values
	3.	Skips downloading if unchanged

This ensures efficient daily operation.

â¸»

## Snake Case Conversion

The script uses this logic:
	â€¢	Remove punctuation
	â€¢	Insert underscores between words
	â€¢	Split camelCase
	â€¢	Convert to lowercase
	â€¢	Collapse multiple underscores

### Example:

#### Input:

"Patients' Rating of the Facility Linear Mean Score"

#### Output:

patients_rating_of_the_facility_linear_mean_score

All downloaded CSV headers have been automatically processed by pandas and overwritten in snake_case.

â¸»

## Sample Output Verification

### Use:

head -n 1 data/*/*.csv

### Example output:

facility_id,facility_name,address,city_town,state,zip_code,...

This confirms snake_case conversion.
